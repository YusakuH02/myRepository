{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNC6PnWtixqb7epfVvG7fzu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YusakuH02/myRepository/blob/main/langchain_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!pip install openai langchain llama-index google-search-results faiss-cpu"
      ],
      "metadata": {
        "id": "Dx4k_VEF0zYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai\n",
        "!pip install faiss-cpu tiktoken chromadb"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7Mjkx8_c0y9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hRDSF0bo1bOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    openai_api_key=\"***your key***\"\n",
        ")\n",
        "\n",
        "response = llm([HumanMessage(content=\"LangChainは動作していますか\")])\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "id": "m76yQ80p5w7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# URL定義（問題と解答）\n",
        "url_202406_Q = \"https://www.ipa.go.jp/shiken/mondai-kaiotu/m42obm000000afqx-att/2024r06a_ap_pm_qs.pdf\"\n",
        "url_202406_A = \"https://www.ipa.go.jp/shiken/mondai-kaiotu/m42obm000000afqx-att/2024r06a_ap_pm_ans.pdf\"\n",
        "\n",
        "# 問題PDFのダウンロード\n",
        "response_202406_Q = requests.get(url_202406_Q)\n",
        "with open(\"202406_ap_pm_question.pdf\", \"wb\") as f:\n",
        "    f.write(response_202406_Q.content)\n",
        "\n",
        "# 解答PDFのダウンロード\n",
        "response_202406_A = requests.get(url_202406_A)\n",
        "with open(\"202406_ap_pm_answer.pdf\", \"wb\") as f:\n",
        "    f.write(response_202406_A.content)"
      ],
      "metadata": {
        "id": "HhbtiA4_CJMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fitzでテキスト分割"
      ],
      "metadata": {
        "id": "uW6JCTUyJXEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "x = 0\n",
        "def extract_text_from_pdf(x, pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for i, page in enumerate(doc):\n",
        "        if i < x:\n",
        "            continue  # 不要なページのスキップ\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "#pdf_text_202406_Q = extract_text_from_pdf(6, \"202406_ap_pm_question.pdf\")\n",
        "pdf_text_202406_A = extract_text_from_pdf(0, \"202406_ap_pm_answer.pdf\")"
      ],
      "metadata": {
        "id": "lfbgrPQtDies"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OCRで画像認識して問題pdfをテキストに"
      ],
      "metadata": {
        "id": "zVwQtyveJb94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install poppler-utils\n",
        "!pip install pdf2image pytesseract"
      ],
      "metadata": {
        "collapsed": true,
        "id": "j19j0Gw4JkdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install tesseract-ocr-jpn"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fCDSBwOsJtcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "# OCR対象のPDFファイル\n",
        "pdf_path = \"202406_ap_pm_question.pdf\"\n",
        "\n",
        "# 画像に変換\n",
        "images = convert_from_path(pdf_path)\n",
        "\n",
        "# OCRでテキスト抽出\n",
        "ocr_text = \"\"\n",
        "for i, image in enumerate(images):\n",
        "    text = pytesseract.image_to_string(image, lang=\"jpn\")  # 日本語対応\n",
        "    ocr_text += f\"\\n--- Page {i + 1} ---\\n{text}\"\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "R3od0PNmJ3Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_text_202406_Q = ocr_text"
      ],
      "metadata": {
        "id": "aaHG0Y1dNCbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50,\n",
        ")\n",
        "\n",
        "docs_202406_Q = text_splitter.create_documents([pdf_text_202406_Q])\n",
        "docs_202406_A = text_splitter.create_documents([pdf_text_202406_A])"
      ],
      "metadata": {
        "id": "t2C34C9SMOp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"1つ目のチャンク内容:\")\n",
        "#print(docs_202406_Q[0].page_content)\n",
        "print(docs_202406_A[0].page_content)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Y35kDud4NWZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oisW2pfgNd25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=\"***your key***\"\n",
        ")"
      ],
      "metadata": {
        "id": "csuxv4VVNu1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore_q = FAISS.from_documents(docs_202406_Q, embeddings)\n",
        "vectorstore_a = FAISS.from_documents(docs_202406_A, embeddings)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JFmNnkdZNqcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 一定文字数以下 or 空白が多すぎるチャンクを除外\n",
        "filtered_docs = [\n",
        "    d for d in docs_202406_Q\n",
        "    if len(d.page_content.strip()) > 200 and \"問\" in d.page_content\n",
        "]"
      ],
      "metadata": {
        "id": "LW6g1RUVd9ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, d in enumerate(docs_202406_Q[:10]):\n",
        "    print(f\"\\n--- Chunk {i} ---\\n\")\n",
        "    print(d.page_content[:800])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "aYH38kUDeSdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"プログラミング分野の問題を一題出題してください\"\n",
        "retrieved_question = vectorstore_q.similarity_search(query, k=1)[0].page_content\n",
        "\n",
        "print(\"📝 問題：\\n\", retrieved_question)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CmptL13jYCdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_answer = input(\"あなたの回答を入力してください：\\n\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Xf0Rz1HkcxWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_answer = vectorstore_a.similarity_search(retrieved_question, k=1)[0].page_content\n",
        "\n",
        "feedback_prompt = f\"\"\"\n",
        "以下は応用情報技術者試験の問題とその模範解答です。\n",
        "\n",
        "【問題】\n",
        "{retrieved_question}\n",
        "\n",
        "【模範解答】\n",
        "{retrieved_answer}\n",
        "\n",
        "【ユーザーの回答】\n",
        "{user_answer}\n",
        "\n",
        "このユーザーの回答が適切かどうかを評価してください。不足があれば解説と修正案を提示してください。また、関連する知識やポイントがあれば追加で教えてください。\n",
        "\"\"\"\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    openai_api_key=\"***your key***\"\n",
        ")\n",
        "response = llm([HumanMessage(content=feedback_prompt)])\n",
        "\n",
        "print(\"フィードバック：\\n\", response.content)\n"
      ],
      "metadata": {
        "id": "U76oYGH2cyXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "↓問題の概要について答えるだけ"
      ],
      "metadata": {
        "id": "mzc-uCjUfw2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    openai_api_key=\"***your key***\"\n",
        "),\n",
        "    retriever=vectorstore.as_retriever(),\n",
        ")\n",
        "\n",
        "result = qa_chain.run(\"問3の内容を簡単に説明してください\")\n",
        "\n",
        "print(\"回答：\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "iJaBIxWSQyRr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}